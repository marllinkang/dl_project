{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 13:37:23.935474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:746] failed to allocate 41.27MiB (43272192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-11-27 13:37:23.935763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:746] failed to allocate 41.27MiB (43272192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-11-27 13:37:33.937444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:746] failed to allocate 41.27MiB (43272192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-11-27 13:37:33.939132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:746] failed to allocate 41.27MiB (43272192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-11-27 13:37:33.939199: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 144.0KiB (rounded to 147456)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-27 13:37:33.939225: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-27 13:37:33.939253: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 20, Chunks in use: 20. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 1.1KiB client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939274: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939294: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939314: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 3, Chunks in use: 2. 9.8KiB allocated for chunks. 7.0KiB in use in bin. 6.8KiB client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939332: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 4.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939349: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939366: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939382: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939404: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939425: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 1. 280.8KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939442: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939460: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939476: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939492: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939508: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939524: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939540: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939556: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939579: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 78.23MiB allocated for chunks. 78.23MiB in use in bin. 72.00MiB client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939596: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939612: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-27 13:37:33.939631: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 144.0KiB was 128.0KiB, Chunk State: \n",
      "2023-11-27 13:37:33.939662: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 136.8KiB | Requested Size: 72.0KiB | in_use: 0 | bin_num: 9, prev:   Size: 3.5KiB | Requested Size: 3.4KiB | in_use: 1 | bin_num: -1, next:   Size: 72.0KiB | Requested Size: 72.0KiB | in_use: 1 | bin_num: -1\n",
      "2023-11-27 13:37:33.939678: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 82556928\n",
      "2023-11-27 13:37:33.939697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000000 of size 256 next 1\n",
      "2023-11-27 13:37:33.939714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000100 of size 1280 next 2\n",
      "2023-11-27 13:37:33.939728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000600 of size 256 next 3\n",
      "2023-11-27 13:37:33.939741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000700 of size 256 next 4\n",
      "2023-11-27 13:37:33.939754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000800 of size 256 next 6\n",
      "2023-11-27 13:37:33.939768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000900 of size 256 next 7\n",
      "2023-11-27 13:37:33.939781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000a00 of size 256 next 5\n",
      "2023-11-27 13:37:33.939795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000b00 of size 256 next 8\n",
      "2023-11-27 13:37:33.939808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000c00 of size 256 next 13\n",
      "2023-11-27 13:37:33.939821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000d00 of size 256 next 11\n",
      "2023-11-27 13:37:33.939835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000e00 of size 256 next 12\n",
      "2023-11-27 13:37:33.939848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432000f00 of size 256 next 16\n",
      "2023-11-27 13:37:33.939861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432001000 of size 256 next 17\n",
      "2023-11-27 13:37:33.939875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432001100 of size 256 next 20\n",
      "2023-11-27 13:37:33.939888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432001200 of size 256 next 21\n",
      "2023-11-27 13:37:33.939901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432001300 of size 256 next 22\n",
      "2023-11-27 13:37:33.939914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432001400 of size 256 next 23\n",
      "2023-11-27 13:37:33.939929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7ff432001500 of size 4608 next 9\n",
      "2023-11-27 13:37:33.939943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432002700 of size 3584 next 10\n",
      "2023-11-27 13:37:33.939957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432003500 of size 256 next 25\n",
      "2023-11-27 13:37:33.939970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432003600 of size 256 next 24\n",
      "2023-11-27 13:37:33.939983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432003700 of size 256 next 26\n",
      "2023-11-27 13:37:33.939996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432003800 of size 256 next 29\n",
      "2023-11-27 13:37:33.940010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7ff432003900 of size 2816 next 27\n",
      "2023-11-27 13:37:33.940022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432004400 of size 3584 next 28\n",
      "2023-11-27 13:37:33.940036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7ff432005200 of size 140032 next 15\n",
      "2023-11-27 13:37:33.940050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432027500 of size 73728 next 14\n",
      "2023-11-27 13:37:33.940065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7ff432039500 of size 73728 next 30\n",
      "2023-11-27 13:37:33.940079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff43204b500 of size 73728 next 19\n",
      "2023-11-27 13:37:33.940093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff43205d500 of size 147456 next 18\n",
      "2023-11-27 13:37:33.940107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7ff432081500 of size 82027264 next 18446744073709551615\n",
      "2023-11-27 13:37:33.940122: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-11-27 13:37:33.940139: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 20 Chunks of size 256 totalling 5.0KiB\n",
      "2023-11-27 13:37:33.940157: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-27 13:37:33.940172: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2023-11-27 13:37:33.940189: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 73728 totalling 144.0KiB\n",
      "2023-11-27 13:37:33.940206: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2023-11-27 13:37:33.940223: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 82027264 totalling 78.23MiB\n",
      "2023-11-27 13:37:33.940241: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 78.52MiB\n",
      "2023-11-27 13:37:33.940258: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 82556928 memory_limit_: 125829120 available bytes: 43272192 curr_region_allocation_bytes_: 251658240\n",
      "2023-11-27 13:37:33.940281: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       125829120\n",
      "InUse:                        82335744\n",
      "MaxInUse:                     82549248\n",
      "NumAllocs:                          52\n",
      "MaxAllocSize:                 82027264\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-27 13:37:33.940337: W tensorflow/tsl/framework/bfc_allocator.cc:497] *********************************************************************************************xxxxxxx\n",
      "2023-11-27 13:37:33.940388: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at stateless_random_ops_v2.cc:64 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[3,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/kang/dev_ws/deep_learning/deep_running/dl_project/dl_webcam.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kang/dev_ws/deep_learning/deep_running/dl_project/dl_webcam.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kang/dev_ws/deep_learning/deep_running/dl_project/dl_webcam.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 딥 러닝 모델 로드\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kang/dev_ws/deep_learning/deep_running/dl_project/dl_webcam.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39m./light_on/light_on_off_model.keras\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# 모델 파일의 경로를 지정\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kang/dev_ws/deep_learning/deep_running/dl_project/dl_webcam.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# 웹캠 열기\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/dev_ws/deep_learning/deep_running/dl_project/dl_webcam.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/saving/saving_api.py:254\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    250\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following argument(s) are not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith the native Keras format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[39m=\u001b[39;49msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:281\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    278\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:246\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 246\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    247\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    250\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:728\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m safe_mode_scope \u001b[39m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    727\u001b[0m \u001b[39mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 728\u001b[0m     instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(inner_config)\n\u001b[1;32m    729\u001b[0m     build_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbuild_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    730\u001b[0m     \u001b[39mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/engine/sequential.py:471\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    465\u001b[0m     use_legacy_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodule\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m layer_config\n\u001b[1;32m    466\u001b[0m     layer \u001b[39m=\u001b[39m layer_module\u001b[39m.\u001b[39mdeserialize(\n\u001b[1;32m    467\u001b[0m         layer_config,\n\u001b[1;32m    468\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    469\u001b[0m         use_legacy_format\u001b[39m=\u001b[39muse_legacy_format,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 471\u001b[0m     model\u001b[39m.\u001b[39;49madd(layer)\n\u001b[1;32m    473\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    474\u001b[0m     \u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39minputs\n\u001b[1;32m    475\u001b[0m     \u001b[39mand\u001b[39;00m build_input_shape\n\u001b[1;32m    476\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(build_input_shape, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[1;32m    477\u001b[0m ):\n\u001b[1;32m    478\u001b[0m     model\u001b[39m.\u001b[39mbuild(build_input_shape)\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/venv/deep_running/lib/python3.10/site-packages/keras/src/backend.py:2102\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2101\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2102\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[1;32m   2103\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   2104\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[1;32m   2105\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[1;32m   2106\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2107\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   2108\u001b[0m     )\n\u001b[1;32m   2109\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   2110\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2111\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2115\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2] name: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 딥 러닝 모델 로드\n",
    "model = load_model('./light_on/light_on_off_model.keras')  # 모델 파일의 경로를 지정\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # 웹캠에서 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.putText(frame, \"light ON, OFF Check\", (400,400), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "\n",
    "    # 전처리: 크기 조정 등 모델의 입력에 맞게 프레임을 전처리해야 함\n",
    "    # 이 부분은 모델이 학습된 입력 형식에 맞게 적절히 수정해주세요.\n",
    "    processed_frame = cv2.resize(frame, (195, 195))\n",
    "    processed_frame = processed_frame / 255.0  # 모델이 학습할 때 정규화되었는지 확인\n",
    "\n",
    "    # 모델 예측\n",
    "    input_array = np.expand_dims(processed_frame, axis=0)  # 모델은 배치 차원을 기대하므로 차원 확장\n",
    "    predictions = model.predict(input_array)\n",
    "\n",
    "    # 예측 결과\n",
    "    # 이 부분은 예측 결과를 어떻게 처리할지에 따라 수정해야 합니다.\n",
    "    # 여기서는 간단하게 클래스별로 확률을 출력합니다.\n",
    "\n",
    "    # class_probabilities = predictions[0]\n",
    "    # class_index = np.argmax(class_probabilities)\n",
    "    # class_label = f\"Light Check: {class_index}, Probability(%): {class_probabilities[class_index]*100:.4f}\"\n",
    "\n",
    "    class_probabilities = predictions[0]\n",
    "    class_index = np.argmax(class_probabilities)\n",
    "\n",
    "    # class_labels 리스트에 \"OFF\"와 \"ON\"을 순서대로 넣어둔다고 가정합니다.\n",
    "    class_labels = [\"OFF\", \"ON\"]\n",
    "\n",
    "    # class_index를 기반으로 클래스 레이블 설정\n",
    "    class_label = class_labels[class_index]\n",
    "\n",
    "    # 확률을 퍼센트로 변환하여 문자열 구성\n",
    "    class_probability_percent = class_probabilities[class_index] * 100\n",
    "    class_label_text = f\"Light Check: {class_label}, Probability(%): {class_probability_percent:.4f}\"\n",
    "\n",
    "    # 결과를 화면에 출력\n",
    "    cv2.putText(frame, class_label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 10, 0), 2)\n",
    "\n",
    "    # class_probabilities = predictions[0]\n",
    "    # class_index = np.argmax(class_probabilities)\n",
    "    # class_label = class_labels[class_index]\n",
    "    # class_probability = class_probabilities[class_index]\n",
    "    # class_label_text = f\"Light Check: {class_label}, Probability: {class_probability:.4f}\"\n",
    "    \n",
    "    # class_probabilities = predictions[0]\n",
    "    # class_index = np.argmax(class_probabilities)\n",
    "    # class_label = f\"Light Check: {class_labels[class_index]}\"\n",
    "    # class_probability = f\"Probability: {class_probabilities[class_index]:.4f}\"\n",
    "    # class_label_text = f\"{class_label}, {class_probability}\"\n",
    "\n",
    "\n",
    "\n",
    "    # 화면에 프레임 표시\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 웹캠 해제 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.3795502e-05, 9.9994624e-01], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_running",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
